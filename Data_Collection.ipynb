{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Collection",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leahgriffith123/SN-Classifier/blob/master/Data_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR17znEs9_GM"
      },
      "source": [
        "# Imports and Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSVf6K97G-u7"
      },
      "source": [
        "**Google Authentication**\n",
        "It should be possible to access all data if Leah_SURF folder is shared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzaS96DexIr6"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfdNIu3iB0uN"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elm1cR_bG6l6"
      },
      "source": [
        "**General Purpose**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4dbaz136cdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "28d9c713-1698-4651-9027-f98d22c65f23"
      },
      "source": [
        "import tqdm\n",
        "import pandas as pd\n",
        "import json\n",
        "from bson.json_util import loads, dumps\n",
        "import gzip\n",
        "import os\n",
        "import io\n",
        "from typing import Union\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from astropy.io import fits\n",
        "from astropy.time import Time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "!pip install xlrd\n",
        "!pip install psycopg2\n",
        "import psycopg2 as ps\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.6/dist-packages (2.7.6.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYY4WapVG2O4"
      },
      "source": [
        "**Kowalski Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-FLrTNt6jbM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "94f01261-1022-4f6c-f3ff-c55e3b3a5893"
      },
      "source": [
        "!pip install git+https://github.com/dmitryduev/kowalski.git\n",
        "!pip install pymongo\n",
        "\n",
        "from IPython.core.display import display, HTML, JSON\n",
        "import json\n",
        "from bson.json_util import dumps, loads \n",
        "\n",
        "\n",
        "from penquins import Kowalski"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/dmitryduev/kowalski.git\n",
            "  Cloning https://github.com/dmitryduev/kowalski.git to /tmp/pip-req-build-u04uor45\n",
            "  Running command git clone -q https://github.com/dmitryduev/kowalski.git /tmp/pip-req-build-u04uor45\n",
            "Requirement already satisfied: pymongo>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from penquins==1.0.3) (3.10.1)\n",
            "Requirement already satisfied: pytest>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from penquins==1.0.3) (3.6.4)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from penquins==1.0.3) (2.23.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (1.8.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (8.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (47.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (1.12.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.3.0->penquins==1.0.3) (1.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->penquins==1.0.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->penquins==1.0.3) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->penquins==1.0.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->penquins==1.0.3) (2020.6.20)\n",
            "Building wheels for collected packages: penquins\n",
            "  Building wheel for penquins (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for penquins: filename=penquins-1.0.3-cp36-none-any.whl size=4706 sha256=610a8c963c49c42dc690755fb5d43c68f0d8ad47248a44c0f617f86b39914684\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dpluflff/wheels/bd/d1/4d/130550e0acb3c3dc15f45217f25ea42f669bbd43af6e32f2d1\n",
            "Successfully built penquins\n",
            "Installing collected packages: penquins\n",
            "Successfully installed penquins-1.0.3\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (3.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XSPovX8mvw"
      },
      "source": [
        "secrets = {\n",
        "    \"kowalski\": {\n",
        "        \"username\": \"leahgriffith\",\n",
        "        \"password\": \"ExceptionallyStrongPa$$word\"\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Pigg627XRM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5ef49ef6-cd3e-462e-87b1-41b2d95c3c6b"
      },
      "source": [
        "k = Kowalski(username=secrets['kowalski']['username'], password=secrets['kowalski']['password'])\n",
        "\n",
        "\n",
        "connection_ok = k.check_connection()\n",
        "print(f'Connection OK: {connection_ok}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connection OK: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14JtukZq-Uof"
      },
      "source": [
        "# Make Triplets and Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lScdJStU9TU7"
      },
      "source": [
        "def make_triplet(alert, normalize: bool = False):\n",
        "    \"\"\"\n",
        "        Feed in alert packet\n",
        "    \"\"\"\n",
        "    cutout_dict = dict()\n",
        "\n",
        "    for cutout in ('science', 'template', 'difference'):\n",
        "        cutout_data = loads(dumps([alert[f'cutout{cutout.capitalize()}']['stampData']]))[0]\n",
        "\n",
        "        # unzip\n",
        "        with gzip.open(io.BytesIO(cutout_data), 'rb') as f:\n",
        "            with fits.open(io.BytesIO(f.read())) as hdu:\n",
        "                data = hdu[0].data\n",
        "                # replace nans with zeros\n",
        "                cutout_dict[cutout] = np.nan_to_num(data)\n",
        "                # normalize\n",
        "                if normalize:\n",
        "                    cutout_dict[cutout] /= np.linalg.norm(cutout_dict[cutout])\n",
        "\n",
        "        # pad to 63x63 if smaller\n",
        "        shape = cutout_dict[cutout].shape\n",
        "        if shape != (63, 63):\n",
        "            cutout_dict[cutout] = np.pad(cutout_dict[cutout], [(0, 63 - shape[0]), (0, 63 - shape[1])],\n",
        "                                         mode='constant', constant_values=1e-9)\n",
        "\n",
        "    triplet = np.zeros((63, 63, 3))\n",
        "    triplet[:, :, 0] = cutout_dict['science']\n",
        "    triplet[:, :, 1] = cutout_dict['template']\n",
        "    triplet[:, :, 2] = cutout_dict['difference']\n",
        "\n",
        "    return triplet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqj19ASl9a6A"
      },
      "source": [
        "def plot_triplet(tr):\n",
        "    fig = plt.figure(figsize=(8, 2), dpi=120)\n",
        "    ax1 = fig.add_subplot(131)\n",
        "    ax1.axis('off')\n",
        "    ax1.imshow(tr[:, :, 0], origin='upper', cmap=plt.cm.bone, norm=LogNorm())\n",
        "    ax1.title.set_text('Science')\n",
        "    ax2 = fig.add_subplot(132)\n",
        "    ax2.axis('off')\n",
        "    ax2.imshow(tr[:, :, 1], origin='upper', cmap=plt.cm.bone, norm=LogNorm())\n",
        "    ax2.title.set_text('Reference')\n",
        "    ax3 = fig.add_subplot(133)\n",
        "    ax3.axis('off')\n",
        "    ax3.imshow(tr[:, :, 2], origin='upper', cmap=plt.cm.bone)\n",
        "    ax3.title.set_text('Difference')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-iZoc3d-hjP"
      },
      "source": [
        "# Querying"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGF-MRbhLqu-"
      },
      "source": [
        "objectIdExcel = \"https://github.com/leahgriffith123/SN-Classifier/blob/master/ObjectIDsExcelData.xlsx?raw=true\"\n",
        "ObjectIdData = pd.read_excel(objectIdExcel)\n",
        "agnList = list(ObjectIdData['agnObjectIdColumn'])\n",
        "sniList = list(ObjectIdData['sniObjectIdColumn'])\n",
        "sniiList = list(ObjectIdData['sniiObjectIdColumn'])\n",
        "bogusList = list(ObjectIdData['bogusObjectIdColumn'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL2V3WSS_mN_"
      },
      "source": [
        "#!git clone https://github.com/leahgriffith123/SN-Classifier.git\n",
        "#!git init .\n",
        "folder_id = '1Xa0y6DpQRxhElFpapXlrTCuQXBM8-fah'\n",
        "def classification(typeObject):\n",
        "  for indObjectId in typeObject:\n",
        "    q = {\"query_type\": \"find\",\n",
        "     \"query\": {\n",
        "         \"catalog\":\"ZTF_alerts\",\n",
        "         \"filter\": {\"objectId\": indObjectId},\n",
        "         \"projection\": {\"_id\": 0},\n",
        "     }\n",
        "     }\n",
        "    r = k.query(query=q)\n",
        "    alerts = r['result_data']['query_result']\n",
        "    for i in alerts:\n",
        "      triplet = make_triplet(i)\n",
        "      filename = \"'AGN\" + indObjectId +\"'.npy\"\n",
        "      np.save(filename, triplet)\n",
        "    #files.download(filename)\n",
        "    folder = drive.CreateFile({'parents': [{'id': folder_id}]})\n",
        "    folder.SetContentFile(filename)\n",
        "    folder.Upload()\n",
        "\n",
        "# !git add \"'ZTF19acxnemy'.npy\"\n",
        "# !git commit\n",
        "# !git push origin master"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}